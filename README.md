# publication-gateway
This repository provides publication repos that are publicly available but are not hosted under this organization.

### System / Network
#### Training Infra

**[EuroSys'25]** HybridFlow: A Flexible and Efficient RLHF Framework.  
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/volcengine/verl)

**[NSDI'25]** ByteCheckpoint: A Unified Checkpointing System for Large Foundation Model Development. 
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/ByteDance-Seed/ByteCheckpoint)

**[EuroSys'25]** HAP: SPMD DNN Training on Heterogeneous GPU Clusters with Automated Program Synthesis. 
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/alibaba/hap)

**[VLDB'25]** Heta: Distributed Training of Heterogeneous Graph Neural Networks
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/jasperzhong/heta)

**[TNSM]** Dynamic Flow Scheduling for DNN Training Workloads in Data Centers
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/joeyyoung/mlcc)


**[TPDS]** SWIFT: Expedited Failure Recovery for Large-scale DNN Training
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/jasperzhong/swift)

**[KDD]** MSPipe: Efficient Temporal GNN Training via Staleness-aware Pipeline
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/PeterSH6/MSPipe)

**[IPDPS'24]** QSync: Quantization-Minimized Synchronous Distributed Training Across Hybrid Devices
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/bytedance/QSync)


**[Mlsys]** Adaptive Message Quantization and Parallelization for Distributed Full-graph GNN Training
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/raywan-110/AdaQP)

**[NSDIâ€˜23]** BGL: GPU-Efficient GNN Training by Optimizing Graph Data I/O and Preprocessing
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/leodestiny/BGL_NSDI2023)


**[TPDS]** Expediting Distributed DNN Training with Device Topology-Aware Graph Deployment
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/ylxdzsw/tag)


#### Network

**[ICDCS'24]** AdapCC: Making Collective Communication in Distributed Machine Learning Adaptive
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/joeyyoung/adapcc)

#### Inference

**[CLUSTER'25]** SplitQuant: Resource-Efficient LLM Offline Serving on Heterogeneous GPUs via Phase-Aware Model Partition and Adaptive Quantization
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/tonyzhao-jt/LLM-PQ)



